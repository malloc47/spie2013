%  article.tex (Version 3.3, released 19 January 2008)
%  Article to demonstrate format for SPIE Proceedings
%  Special instructions are included in this file after the
%  symbol %>>>>
%  Numerous commands are commented out, but included to show how
%  to effect various options, e.g., to print page numbers, etc.
%  This LaTeX source file is composed for LaTeX2e.

%  The following commands have been added in the SPIE class 
%  file (spie.cls) and will not be understood in other classes:
%  \supit{}, \authorinfo{}, \skiplinehalf, \keywords{}
%  The bibliography style file is called spiebib.bst, 
%  which replaces the standard style unstr.bst.  

\documentclass[]{spie}  %>>> use for US letter paper
%%\documentclass[a4paper]{spie}  %>>> use this instead for A4 paper
%%\documentclass[nocompress]{spie}  %>>> to avoid compression of citations
%% \addtolength{\voffset}{9mm}   %>>> moves text field down
%% \renewcommand{\baselinestretch}{1.65}   %>>> 1.65 for double spacing, 1.25 for 1.5 spacing 
%  The following command loads a graphics package to include images 
%  in the document. It may be necessary to specify a DVI driver option,
%  e.g., [dvips], but that may be inappropriate for some LaTeX 
%  installations. 
\usepackage[]{graphicx}

\usepackage{subfig}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algpseudocode}
\usepackage{algorithm}

\input{functions.tex}

\title{Interactive Grain Image Segmentation using Graph Cut Algorithms} 

%>>>> The author is responsible for formatting the 
%  author list and their institutions.  Use  \skiplinehalf 
%  to separate author list from addresses and between each address.
%  The correspondence between each author and his/her address
%  can be indicated with a superscript in italics, 
%  which is easily obtained with \supit{}.

\author{Jarrell Waggoner\supit{a}, Youjie Zhou\supit{a}, Jeff Simmons\supit{b}, Ayman Salem\supit{b}, \\ Marc De Graef\supit{c}, and Song Wang\supit{a}
\skiplinehalf
\supit{a}University of South Carolina, Columbia, SC 29208, USA; \\
\supit{b}Materials and Manufacturing Directorate, Air Force Research
Labs, Dayton, OH 45433, USA; \\
\supit{c} Carnegie Mellon University, Department of Materials Science and Engineering, 5000 Forbes Avenue, Pittsburgh, PA, 15213, USA
}

%>>>> Further information about the authors, other than their 
%  institution and addresses, should be included as a footnote, 
%  which is facilitated by the \authorinfo{} command.

\authorinfo{Further author information: (Send correspondence to J.W.)\\
J.W.: E-mail: waggonej@email.sc.edu, Telephone: 847-261-4747\\ 
Y.Z.: E-mail: zhou42@email.sc.edu \\ 
J.S.: E-mail: jeff.simmons@wpafb.af.mil \\ 
A.S.: E-mail: ayman.salem.ctr@wpafb.af.mil \\ 
M.G.: E-mail: degraef@cmu.edu \\
S.W.: E-mail: songwang@cec.sc.edu, Telephone: 803-777-2487}
%%>>>> when using amstex, you need to use @@ instead of @
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%>>>> uncomment following for page numbers
% \pagestyle{plain}    
%>>>> uncomment following to start page numbering at 301 
%\setcounter{page}{301} 
 
  \begin{document} 
  \maketitle 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{abstract}
% \input{spie-abstract.tex}
\input{abstract.tex}
\end{abstract}

%>>>> Include a list of keywords after the abstract 

\keywords{Segmentation, Materials, Propagation, Interactive, Graph-Cut}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

Interactive segmentation is a rapidly-growing area of Computer Vision
and has seen heightened interest recently\cite{kuang:12,straehle:12}.
While traditional segmentation seeks to identify objects/structures
within an image in a fully-automated fashion, interactive
segmentation, similar to Active Learning~\cite{settles:09},
accomplishes the same goal using a sparse number of user interactions.
These interactions may take on different forms, and may include
drawing a bounding box~\cite{rother:04}, roughly outlining a
boundary~\cite{mortensen:95}, or drawing brush strokes inside and/or
outside the object of interest~\cite{santner:10, unger:08, boykov:01b,
  vezhnevets:95}.  A desired property of an interactive segmentation
approach is that the user interaction be as convenient (\ie low
cognitive load) and sparse (\ie few in number) as possible, while
simultaneously providing immediate feedback to the user on every
interaction.

Many existing methods segment the object of interest using a model
learned from the user interactions~\cite{boykov:01b, unger:08,
  rother:04}.  Other approaches use morphological operations
(watershed)~\cite{straehle:12}, rely on
co-segmentation~\cite{batra:10}, or incorporate machine-learning to
aid in the interactive process~\cite{top:11, kuant:12}.  These methods
have been applied to a number of domains, including natural
images~\cite{rother:04}, medical images~\cite{boykov:00}, and
neuroimages~\cite{straehle:11, straehle:12}.

One domain that has been unaddressed in interactive segmentation
literature is Materials Science image segmentation, where there are no
existing techniques focusing solely on segmenting materials images
using an interactive approach.  Materials science is especially
important to the development of new metals and biomaterials, and
presents unique challenges in image segmentation.  First, materials
images are often segmented in volumes~\cite{ibrahim:91} consisting of
individual image ``slices'' along the z-axis, producing numerous
images that must all be segmented to fully and properly analyze the
volume.  Second, depending on the inter-slice distance, a slice may
share large overlap with its neighboring slices.  This results in
slices being very coherent from one slice to the next, requiring that
segmentation methods handle this coherency to obtain accurate
segmentation.  Third, materials volumes consist of numerous
substructures (\eg,``grains'' in a metallic material, or ``cells'' in
a biomaterial, etc.) with complex relationships (\eg,
adjacency/nonadjacency relationships) among them that determine many
desirable properties of the material~\cite{swiler:95, rollett:04}.
Existing interactive segmentation techniques often focus on only
foreground-background segmentation~\cite{rother:04, boykov:01b}, and
may not scale to the large number of substructures present in
materials images.  Other methods may handle multiple
structures~\cite{straehle:11, straehle:12}, but do not incorporate any
prior knowledge about the unique relationships among
substructures~\cite{reed:06, tan:04}.  Finally, the imaging techniques
used to obtain a materials image volume may result in significant
noise or other ambiguities that makes fully-automated segmentation
difficult or impossible.  As we discuss next, existing techniques do
not address all of these challenges.

There are a number of existing, non-interactive approaches to segment
materials images~\cite{chuang:08, simmons:09}.  Among the most
prominent is the work of Comer~\etal~\cite{comer:94, comer:00} on the
EM/MPM algorithm, originating from~\cite{marroquin:87} .  Other
methods that have been specifically used on materials images include
graph cut~\cite{landis:11, waggoner:11}, stabilized inverse diffusion
equations~\cite{huffman:08}, Bayesian methods~\cite{comer:11,
  simmons:08}, and the watershed~\cite{liq:07} method.  Most often,
materials images are opportunistically segmented by the simplest tools
available, such as thresholding~\cite{gonzalez:08,shapiro:01}, or
out-of-the-box methods such as watershed or normalized cut.  All of
these techniques are able to achieve reasonable results in a
fully-automated fashion, however, they do not incorporate any
interaction for manual refinement by a user.  Since some of these
approaches may require significant time to run, requiring the user to
examine and correct problems only after the algorithm is complete may
not be practical if rapid-turnaround segmentation is desired.
Conversely, the interactive segmentation techniques discussed
previously do not incorporate any specific domain knowledge about
materials images, and thus may require additional effort on the part
of the user than may otherwise be needed when segmenting a materials
image volume.

In this paper, we present an interactive segmentation approach to
segment materials science image volumes.  We show that an existing
propagation-based materials image segmentation
approach~\cite{waggoner:11} can be extended to allow for convenient
interactive segmentation.  We illustrate the performance of the
proposed approach by using it to segment a materials image volume
using smaller number of interactions compared with other methods that
do not incorporate materials-specific priors.  Finally, we develop
methods to estimate the parameters of this proposed approach to
further reduce the number of user-required interactions in the
segmentation process.

The remainder of this paper is organized as follows: in
\sect{interactive} we discuss the proposed interactive segmentation
approach for materials image volumes. In \sect{param}, we show how
some of the parameters of the proposed method.  In \sect{ex}, we
evaluate the proposed method's performance against another interactive
segmentation method.  Finally, in \sect{conclusion} we provide brief
concluding remarks.

\section{Interactive Materials Segmentation}
\label{sec:interactive}

In previous work~\cite{waggoner:11}, volume segmentation was
formulated as a propagation from the segmentation initialization $S^U$
of a slice $U$ through the remaining slices to segment the complete
volume, using an energy minimization formulation of the form
\begin{equation}
  E( S^V ) = \sum_{p\in V}\Theta_p(S^V_i) + 
  \sum_{\{p,q\}\in\mathcal{P}^V_n} \Phi_{pq}(S_i^V , S_j^V) .
\label{eq:energy1}
\end{equation}
where the \data{} term $\Theta_p(S^V_i)$ was set using a dilation from
the initialization $S^U$ and the \smooth{} term $\Phi_{pq}(S_i^V ,
S_j^V)$ was constrained to preserve \emph{non-adjacency} among the
different segments
\[S^V = \{ S^V_1, S^V_2, \ldots, S^V_n \} \] using their same
adjacency relations from $S^U$.

This formulation was shown to be minimizable to a local
optimum~\cite{veksler:99, boykov:01}.  For interaction, our desire is
to update the resulting segmentation $S^V$ by interactively allowing
the user to specify areas for correction and producing a corrected
$\tilde{S}^V$ segmenation.  We propose to allow the user to correct two
types of segmentation errors within this framework: 1)
oversegmentation, where a single structure is erroneously segmented
into multiple structures and one or more must be removed/merged, and
2) undersegmentation, where one or more structures are not assigned to
a segment, and a new segmentation should be introduced for these
structures.  Other errors, such as misplaced boundaries, can be
corrected by combinations of the above operations, \eg, merging two
segments and then introducing a new segment at the correct location.

While the previous method~\cite{waggoner:11} segmented entire slices,
for performance, we wish to restrict the interaction to small, local
regions within a structure.  We will further discuss the two
approaches, and how we identify local regions for each, in the
following subsections.

\subsection{Removal: Correcting Oversegmentation}

We allow the user to select a specific segment $S^V_k$ for removal by
interactively clicking on this segment in a visualized segmentation.
Instead of naively removing this segment by arbitrarily merging it
into one of its neighbors, we instead find a local group of segments
around the identified segment, as shown by $a_1, a_2, a_3$ around the
selected segment $S^V_k$ in \figsub{removal-ex}{a}, and re-run the
previous energy minimization within this local region after modifying
the $\Theta$ term to incorporate the interaction, resulting in
\figsub{removal-ex}{b}.
\begin{figure}[htbp]
\centering
\subfloat{\includegraphics[width=0.33\linewidth]{fig/aaa.pdf}}
\hspace{0.1em}
\subfloat{\includegraphics[width=0.33\linewidth]{fig/aac}}
\caption{Example selection of $S^V_k$ for removal.  \textbf{(a)}
  Chosen $S^V_k$ and surrounding segments.  \textbf{(b)} Local region
  extracted and energy minimized in this
  region.} \label{fig:removal-ex}
\end{figure}
More generally, for ease of notation, we use $ \mathcal{A}_k = \{a_1,
\ldots, a_m\} $ to refer to the set of segments neighboring any
particular segment $S^V_k$.  We do this by setting an infinity penalty
for the indicated segment $S^V_k$ and zero penalty for all other
surrounding segments.

More specifically, to update the $\Theta$ term, we incorporate these
adjacent neighbors by allowing all the pixels $p\in S^V_k$ to be
assigned any of its neighboring label's segments, \ie,
\begin{equation}\label{eq:remove}
\begin{aligned}
 \forall p \in S^V_k ,& \quad \Theta_p(\tilde{S}^V_i) = \left\{
   \begin{array}{lcr}
     0, & S^V_i \in \mathcal{A}_k \textrm{ and } i \neq k  \\
     \infty, & \textrm{ otherwise} \\
   \end{array}
 \right. \\
\forall p \notin S^V_k ,& \quad \Theta_p(\tilde{S}^V_i) = \Theta_p(S^V_i)
\end{aligned}
\end{equation}

% \begin{align*}
%  \forall p \in S^V_k , & \\
%  % & \Theta_p(\tilde{S}^V_k) = \infty \\
%  & \Theta_p(\tilde{S}^V_i) = \left\{
%    \begin{array}{lcr}
%      0, & S^V_i \in \mathcal{A}_k \textrm{ and } i \neq k  \\
%      \infty, & \textrm{ otherwise} \\
%    \end{array}
% \right. % , \textrm{ where } i \neq k
% \\
% \forall p \notin S^V_k , & \\ 
% & \Theta_p(\tilde{S}^V_i) = \Theta_p(S^V_i)
% \end{align*}

which results in all pixels $p$ that were previously in $S^V_k$ being
assigned an $\infty$ penalty in $\tilde{S}^V$, while being given a $0$
cost if they are assigned to the neighbors of $S^V_k$ in
$\tilde{S}^V$.  For other pixels $p\notin S^V_k$, their costs in
$\tilde{S}^V_k$ remain exactly as they were in $S^V_k$.  By updating
$\Theta$ in this fashion, we reassign the segments surrounding $S^V_k$
to all of its pixels, but we do not require that $S^V_k$ be reassigned
to a single segment.  Thus the energy minimization may reassign the
some pixels in $S^V_k$ to one segment, and other pixels to another
segment, as shown in \figsub{removal-ex}{b}.

The interaction required by the user for removal of a segment is very
minimal---a single click anywhere inside of the desired $S^V_k$
segment is all that is necessary for the system to complete the
operation.  The full algorithm for removal is shown in \alg{remove}.

\begin{algorithm}[!t]
  \centering
  \algrenewcommand\algorithmicforall{\textbf{for each}}
  \begin{algorithmic}[1]
    \Function{RemoveSegment}{$S^V, S^V_k$}
    \State $A_k \gets$ neighbors for $S^V_k$
    \State Identify region surrounding $S^V_k$ and $A_k$
    \State Within region, setup energy minimization problem from~\cite{waggoner:11}
    \State $\Theta \gets $ set from \eq{remove}
    \State $ \tilde{S}^V \gets $ minimization of energy in local region and copied to $S^V$
    \State \textbf{return} updated $\tilde{S}^V$
    \EndFunction
  \end{algorithmic}
  \caption{Interactively specifying segment to remove.}
  \label{alg:remove}
\end{algorithm}

\subsection{Addition: Correcting Undersegmentation}



\section{Parameter Estimation}
\label{sec:param}

\section{Experiments}
\label{sec:ex}

\section{Conclusion}
\label{sec:conclusion}

\bibliography{matsci}
\bibliographystyle{spiebib}   %>>>> makes bibtex use spiebib.bst

\end{document} 
