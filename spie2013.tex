%  article.tex (Version 3.3, released 19 January 2008)
%  Article to demonstrate format for SPIE Proceedings
%  Special instructions are included in this file after the
%  symbol %>>>>
%  Numerous commands are commented out, but included to show how
%  to effect various options, e.g., to print page numbers, etc.
%  This LaTeX source file is composed for LaTeX2e.

%  The following commands have been added in the SPIE class 
%  file (spie.cls) and will not be understood in other classes:
%  \supit{}, \authorinfo{}, \skiplinehalf, \keywords{}
%  The bibliography style file is called spiebib.bst, 
%  which replaces the standard style unstr.bst.  

\documentclass[]{spie}  %>>> use for US letter paper
%%\documentclass[a4paper]{spie}  %>>> use this instead for A4 paper
%%\documentclass[nocompress]{spie}  %>>> to avoid compression of citations
%% \addtolength{\voffset}{9mm}   %>>> moves text field down
%% \renewcommand{\baselinestretch}{1.65}   %>>> 1.65 for double spacing, 1.25 for 1.5 spacing 
%  The following command loads a graphics package to include images 
%  in the document. It may be necessary to specify a DVI driver option,
%  e.g., [dvips], but that may be inappropriate for some LaTeX 
%  installations. 
\usepackage[]{graphicx}

\usepackage{subfig}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algpseudocode}
\usepackage{algorithm}

\input{functions.tex}

\title{Interactive Grain Image Segmentation using Graph Cut Algorithms} 

%>>>> The author is responsible for formatting the 
%  author list and their institutions.  Use  \skiplinehalf 
%  to separate author list from addresses and between each address.
%  The correspondence between each author and his/her address
%  can be indicated with a superscript in italics, 
%  which is easily obtained with \supit{}.

\author{Jarrell Waggoner\supit{a}, Youjie Zhou\supit{a}, Jeff Simmons\supit{b}, Ayman Salem\supit{b}, \\ Marc De Graef\supit{c}, and Song Wang\supit{a}
\skiplinehalf
\supit{a}University of South Carolina, Columbia, SC 29208, USA; \\
\supit{b}Materials and Manufacturing Directorate, Air Force Research
Labs, Dayton, OH 45433, USA; \\
\supit{c} Carnegie Mellon University, Department of Materials Science and Engineering, 5000 Forbes Avenue, Pittsburgh, PA, 15213, USA
}

%>>>> Further information about the authors, other than their 
%  institution and addresses, should be included as a footnote, 
%  which is facilitated by the \authorinfo{} command.

\authorinfo{Further author information: (Send correspondence to J.W.)\\
J.W.: E-mail: waggonej@email.sc.edu, Telephone: 847-261-4747\\ 
Y.Z.: E-mail: zhou42@email.sc.edu \\ 
J.S.: E-mail: jeff.simmons@wpafb.af.mil \\ 
A.S.: E-mail: ayman.salem.ctr@wpafb.af.mil \\ 
M.G.: E-mail: degraef@cmu.edu \\
S.W.: E-mail: songwang@cec.sc.edu, Telephone: 803-777-2487}
%%>>>> when using amstex, you need to use @@ instead of @
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%>>>> uncomment following for page numbers
% \pagestyle{plain}    
%>>>> uncomment following to start page numbering at 301 
%\setcounter{page}{301} 
 
  \begin{document} 
  \maketitle 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{abstract}
% \input{spie-abstract.tex}
\input{abstract.tex}
\end{abstract}

%>>>> Include a list of keywords after the abstract 

\keywords{Segmentation, Materials, Propagation, Interactive, Graph-Cut}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

Interactive segmentation is a rapidly-growing area of Computer Vision
and has seen heightened interest recently\cite{kuang:12,straehle:12}.
While traditional segmentation seeks to identify objects/structures
within an image in a fully-automated fashion, interactive
segmentation, similar to Active Learning~\cite{settles:09},
accomplishes the same goal using a sparse number of user interactions.
These interactions may take on different forms, and may include
drawing a bounding box~\cite{rother:04}, roughly outlining a
boundary~\cite{mortensen:95}, or drawing brush strokes inside and/or
outside the object of interest~\cite{santner:10, unger:08, boykov:01b,
  vezhnevets:95}.  A desired property of an interactive segmentation
approach is that the user interaction be as convenient (\ie low
cognitive load) and sparse (\ie few in number) as possible, while
simultaneously providing immediate feedback to the user on every
interaction.

Many existing methods segment the object of interest using a model
learned from the user interactions~\cite{boykov:01b, unger:08,
  rother:04}.  Other approaches use morphological operations
(watershed)~\cite{straehle:12}, rely on
co-segmentation~\cite{batra:10}, or incorporate machine-learning to
aid in the interactive process~\cite{top:11, kuant:12}.  These methods
have been applied to a number of domains, including natural
images~\cite{rother:04}, medical images~\cite{boykov:00}, and
neuroimages~\cite{straehle:11, straehle:12}.

One domain that has been unaddressed in interactive segmentation
literature is Materials Science image segmentation, where there are no
existing techniques focusing solely on segmenting materials images
using an interactive approach.  Materials science is especially
important to the development of new metals and biomaterials, and
presents unique challenges in image segmentation.  First, materials
images are often segmented in volumes~\cite{ibrahim:91} consisting of
individual image ``slices'' along the z-axis, producing numerous
images that must all be segmented to fully and properly analyze the
volume.  Second, depending on the inter-slice distance, a slice may
share large overlap with its neighboring slices.  This results in
slices being very coherent from one slice to the next, requiring that
segmentation methods handle this coherency to obtain accurate
segmentation.  Third, materials volumes consist of numerous
substructures (\eg,``grains'' in a metallic material, or ``cells'' in
a biomaterial, etc.) with complex relationships (\eg,
adjacency/nonadjacency relationships) among them that determine many
desirable properties of the material~\cite{swiler:95, rollett:04}.
Existing interactive segmentation techniques often focus on only
foreground-background segmentation~\cite{rother:04, boykov:01b}, and
may not scale to the large number of substructures present in
materials images.  Other methods may handle multiple
structures~\cite{straehle:11, straehle:12}, but do not incorporate any
prior knowledge about the unique relationships among
substructures~\cite{reed:06, tan:04}.  Finally, the imaging techniques
used to obtain a materials image volume may result in significant
noise or other ambiguities that makes fully-automated segmentation
difficult or impossible.  As we discuss next, existing techniques do
not address all of these challenges.

There are a number of existing, non-interactive approaches to segment
materials images~\cite{chuang:08, simmons:09}.  Among the most
prominent is the work of Comer~\etal~\cite{comer:94, comer:00} on the
EM/MPM algorithm, originating from~\cite{marroquin:87} .  Other
methods that have been specifically used on materials images include
graph cut~\cite{landis:11, waggoner:11}, stabilized inverse diffusion
equations~\cite{huffman:08}, Bayesian methods~\cite{comer:11,
  simmons:08}, and the watershed~\cite{liq:07} method.  Most often,
materials images are opportunistically segmented by the simplest tools
available, such as thresholding~\cite{gonzalez:08,shapiro:01}, or
out-of-the-box methods such as watershed or normalized cut.  All of
these techniques are able to achieve reasonable results in a
fully-automated fashion, however, they do not incorporate any
interaction for manual refinement by a user.  Since some of these
approaches may require significant time to run, requiring the user to
examine and correct problems only after the algorithm is complete may
not be practical if rapid-turnaround segmentation is desired.
Conversely, the interactive segmentation techniques discussed
previously do not incorporate any specific domain knowledge about
materials images, and thus may require additional effort on the part
of the user than may otherwise be needed when segmenting a materials
image volume.

In this paper, we present an interactive segmentation approach to
segment materials science image volumes.  We show that an existing
propagation-based materials image segmentation
approach~\cite{waggoner:11} can be extended to allow for convenient
interactive segmentation.  We illustrate the performance of the
proposed approach by using it to segment a materials image volume
using smaller number of interactions compared with other methods that
do not incorporate materials-specific priors.  Finally, we develop
methods to estimate the parameters of this proposed approach to
further reduce the number of user-required interactions in the
segmentation process.

The remainder of this paper is organized as follows: in
\sect{interactive} we discuss the proposed interactive segmentation
approach for materials image volumes. In \sect{param}, we show how
some of the parameters of the proposed method.  In \sect{ex}, we
evaluate the proposed method's performance against another interactive
segmentation method.  Finally, in \sect{conclusion} we provide brief
concluding remarks.

\section{Interactive Materials Segmentation}
\label{sec:interactive}

In previous work~\cite{waggoner:11}, volume segmentation was
formulated as a propagation from the segmentation initialization $S^U$
of a slice $U$ through the remaining slices to segment the complete
volume, using an energy minimization formulation of the form
\begin{equation}
  E( S^V ) = \sum_{p\in V}\Theta_p(S^V_i) + 
  \sum_{\{p,q\}\in\mathcal{P}^V_n} \Phi_{pq}(S_i^V , S_j^V) .
\label{eq:energy1}
\end{equation}
where the \data{} term $\Theta_p(S^V_i)$ was set using a dilation from
the initialization $S^U$ and the \smooth{} term $\Phi_{pq}(S_i^V ,
S_j^V)$ was constrained to preserve \emph{non-adjacency} among the
different segments
\[S^V = \{ S^V_1, S^V_2, \ldots, S^V_n \} \] using their same
adjacency relations from $S^U$.

This formulation was shown to be minimizable to a local
optimum~\cite{veksler:99, boykov:01}.  For interaction, our desire is
to update the resulting segmentation $S^V$ by interactively allowing
the user to specify areas for correction and producing a corrected
$S^{\tilde{V}}$ segmenation.  We propose to allow the user to correct two
types of segmentation errors within this framework: 1)
oversegmentation, where a single structure is erroneously segmented
into multiple structures and one or more must be removed/merged, and
2) undersegmentation, where one or more structures are not assigned to
a segment, and a new segmentation should be introduced for these
structures.  Other errors, such as misplaced boundaries, can be
corrected by combinations of the above operations, \eg, merging two
segments and then introducing a new segment at the correct location.

While the previous method~\cite{waggoner:11} segmented entire slices,
for performance, we wish to restrict the interaction to small, local
regions within a structure.  We will further discuss the two
approaches, and how we identify local regions for each, in the
following subsections.

\subsection{Removal: Correcting Oversegmentation}
\label{sec:remove}

We allow the user to select a specific segment $S^V_k$ for removal by
interactively clicking on this segment in a visualized segmentation.
Instead of naively removing this segment by arbitrarily merging it
into one of its neighbors, we instead find a local group of segments
around the identified segment, as shown by $a_1, a_2, a_3$ around the
selected segment $S^V_k$ in \figsub{removal-ex}{a}, and re-run the
previous energy minimization within this local region after modifying
the $\Theta$ term to incorporate the interaction, resulting in
\figsub{removal-ex}{b}.
\begin{figure}[htbp]
\centering
\subfloat[]{\includegraphics[width=0.33\linewidth]{fig/aaa.pdf}}
\hspace{0.1em}
\subfloat[]{\includegraphics[width=0.33\linewidth]{fig/aac}}
\caption{Example selection of $S^V_k$ for removal.  \textbf{(a)}
  Chosen $S^V_k$ and surrounding segments.  \textbf{(b)} Local region
  extracted and energy minimized in this
  region.} \label{fig:removal-ex}
\end{figure}
More generally, for ease of notation, we use $ \mathcal{A}_k = \{a_1,
\ldots, a_m\} $ to refer to the set of segments neighboring any
particular segment $S^V_k$.  We do this by setting an infinity penalty
for the indicated segment $S^V_k$ and zero penalty for all other
surrounding segments.

More specifically, to update the $\Theta$ term, we incorporate these
adjacent neighbors by allowing all the pixels $p\in S^V_k$ to be
assigned any of its neighboring label's segments, \ie,
\begin{equation}\label{eq:remove}
\begin{aligned}
 \forall p \in S^V_k ,& \quad \Theta_p(S^{\tilde{V}}_i) = \left\{
   \begin{array}{lcr}
     0, & S^V_i \in \mathcal{A}_k \textrm{ and } i \neq k  \\
     \infty, & \textrm{ otherwise} \\
   \end{array}
 \right. \\
\forall p \notin S^V_k ,& \quad \Theta_p(S^{\tilde{V}}_i) = \Theta_p(S^V_i)
\end{aligned}
\end{equation}

% \begin{align*}
%  \forall p \in S^V_k , & \\
%  % & \Theta_p(S^{\tilde{V}}_k) = \infty \\
%  & \Theta_p(S^{\tilde{V}}_i) = \left\{
%    \begin{array}{lcr}
%      0, & S^V_i \in \mathcal{A}_k \textrm{ and } i \neq k  \\
%      \infty, & \textrm{ otherwise} \\
%    \end{array}
% \right. % , \textrm{ where } i \neq k
% \\
% \forall p \notin S^V_k , & \\ 
% & \Theta_p(S^{\tilde{V}}_i) = \Theta_p(S^V_i)
% \end{align*}

which results in all pixels $p$ that were previously in $S^V_k$ being
assigned an $\infty$ penalty in $S^{\tilde{V}}$, while being given a $0$
cost if they are assigned to the neighbors of $S^V_k$ in
$S^{\tilde{V}}$.  For other pixels $p\notin S^V_k$, their costs in
$S^{\tilde{V}}_k$ remain exactly as they were in $S^V_k$.  By updating
$\Theta$ in this fashion, we reassign the segments surrounding $S^V_k$
to all of its pixels, but we do not require that $S^V_k$ be reassigned
to a single segment.  Thus the energy minimization may reassign the
some pixels in $S^V_k$ to one segment, and other pixels to another
segment, as shown in \figsub{removal-ex}{b}.

The interaction required by the user for removal of a segment is very
minimal---a single click anywhere inside of the desired $S^V_k$
segment is all that is necessary for the system to complete the
operation.  The full algorithm for removal is shown in \alg{remove}.

\begin{algorithm}[!t]
  \centering
  \algrenewcommand\algorithmicforall{\textbf{for each}}
  \begin{algorithmic}[1]
    \Function{RemoveSegment}{$S^V, S^V_k$}
    \State $A_k \gets$ neighbors for $S^V_k$
    \State Identify region surrounding $S^V_k$ and $A_k$
    \State For pixels within region, build graph for energy minimization problem from~\cite{waggoner:11}
    \State $\Theta \gets $ set from \eq{remove}
    \State $ S^{\tilde{V}} \gets $ minimization of energy in local region and copied to $S^V$
    \State \textbf{return} updated $S^{\tilde{V}}$
    \EndFunction
  \end{algorithmic}
  \caption{Interactively specifying segment to remove.}
  \label{alg:remove}
\end{algorithm}

\subsection{Addition: Correcting Undersegmentation}
\label{sec:addition}

Unlike removal, interactively annotating an additional structure
cannot be solely formulated as a simple modification of the $\Theta$
term in the energy minimization formulation.  This is because the
multi-labeling problem used to optimize the energy minimization form
in~\cite{waggoner:11} optimizes over a fixed set of segments, and
cannot create new segments.  Thus, we must explicitly create a new
segment at the location specified by the user.

We take as input from the user, an annotation specifying the center
location $c_{x,y}$ of the new segment $S^{\tilde{V}}_{n+1}$.  In
addition to this, we also accept two parameters from the user: 1) the
\emph{seed} distance $s$ specifying a circular region within the
interior to the desired structure to be segmented; 2) a
\textit{dilation} parameter $d$, which is the same as the dilation
parameter used in~\cite{waggoner:11}, which should completely cover
the structure to be segmented.  We explicitly enforce that $d \geq s$
for any choice of $s$.

We call pixels within the seed distance $s$ of the annotated point
``seed pixels'' and pixels within the dilation distance $d$ of the
annotated point ``dilation pixels.''  Using this approach, seed pixels
are \emph{guaranteed} to be part of the annotated segment, as shown by
the green circle in \figsub{addition-ex}{b}, and dilation pixels are
\emph{potentially} part of the annotated segment, as shown by the blue
circle in \figsub{addition-ex}{b}.  This makes these parameter
conceptually simple for the user to tune.  In \sect{param}, we discuss
how to automate the selection of these parameters to further reduce
the user's burden when interactively segmenting a materials volume.

\begin{figure}[htbp]
\centering
\subfloat[]{\includegraphics[width=0.30\linewidth]{fig/bba}}
\hspace{0.1em}
\subfloat[]{\includegraphics[width=0.30\linewidth]{fig/bbb.pdf}}
\hspace{0.1em}
\subfloat[]{\includegraphics[width=0.30\linewidth]{fig/bbc}}
\caption{Annotating the addition of a segment.  \textbf{(a)}
  Segmentation $S^V$ with a structure that has no corresponding
  segment.  \textbf{(b)} Annotation of a center point $c$, along with
  a seed distance $s$ and a dilation distance $d$.  \textbf{(c)} The
  result of running the proposed method using the annotation from
  (b).} \label{fig:addition-ex}
\end{figure}

Since we define segmentation $S^V$ as having $n$ segments $S^V_1,
S^V_2, \ldots, S^V_n$, we introduce a new $n+1$ segment in the updated
segmentation $S^{\tilde{V}}$.  This $S^{\tilde{V}}_{n+1}$ is
introduced by giving a zero cost for all pixels within the dilation
distance of the annotated point $c$, \ie
\begin{equation}
  \label{eq:d}
  \Theta_p(S^{\tilde{V}}_{n+1}) = \left\{
    \begin{array}{lcr}
      0, & \| p_{x,y} - c_{x,y} \| \leq d  \\
      \infty, & \textrm{ otherwise} \\
    \end{array}
  \right. .
\end{equation}
Though this is necessary to include the new segment in the energy
minimization, it is not sufficient to guarantee that it will appear in
the final segmentation.  To insure that some of pixels near the
annotation are guaranteed to be part of the segmentation, we give an
infinity penalty for pixels within the seed distance $s$ to be
assigned any other segment except $S^{\tilde{V}}_{n+1}$.  Similar to
\eq{d} above, we set
\begin{equation}
  \label{eq:s}
  \Theta_p(S^{\tilde{V}}_i) = \left\{
    \begin{array}{lcr}
      \infty, & \| p_{x,y} - c_{x,y} \| \leq s \textrm{ and } i \neq n+1  \\
      \Theta_p(S^{V}_i), & \textrm{ otherwise} \\
    \end{array}
  \right.
\end{equation}
which \emph{fixes} pixels within the seed distance $s$ of the
annotated point to be assigned only to $S^{\tilde{V}}_{n+1}$; if they
are not, then they take on the same value as they did in the energy
minimization in $S^V$.  Similar to the removal step in \sect{remove},
we can also do this procedure in a local region for efficiency by
finding all segments within the seed distance $s$ of $c$ and find all
adjacent segments to these segments to form the local region.  The
full algorithm for annotating addition is shown in \alg{addition}.
\begin{algorithm}[!t]
  \centering
  \algrenewcommand\algorithmicforall{\textbf{for each}}
  \begin{algorithmic}[1]
    \Function{AddSegment}{$S^V, c_{x,y}$, $s$, $d$}
    \State $A \gets$ neighbors for $\bigcup$ all segments within distance $s$ of $c$
    \State Identify region surrounding $A_k$
    \State For pixels within region, build graph for energy minimization problem from~\cite{waggoner:11}
    \State $\Theta \gets $ set from \eq{d} and \eq{s}
    \State $ S^{\tilde{V}} \gets $ minimization of energy in local region and copied to $S^V$
    \State \textbf{return} updated $S^{\tilde{V}}$
    \EndFunction
  \end{algorithmic}
  \caption{Interactively specifying segment to add.}
  \label{alg:addition}
\end{algorithm}

\section{Parameter Estimation}
\label{sec:param}

When adding new regions, as discussed in \sect{addition}, the seed
distance $s$ and dilation distance $d$ are required to be specified by
the user.  This results in unnecessary interactions on the part of the
user that serve only to provide this information.  Instead, we wish to
provide good estimates for these parameters, so the user need only
override them in very rare cases, or not at all.

We do this by leveraging information about the annotation the user
provided relative to the region in which it resides.  Generally, an
annotation to add a new segment is made because a small structure
within a larger segment is missed.  An example is shown in
\figsub{param}{a}, where the small structure near the right of the
large segment does not have its own segment, and is instead contained
within the large segment in the center.  Intuitively, annotating near
the edge of this large segment likely indicates the resulting new
segment is small.  Conversely, annotating closer to the center of this
large segment likely indicates the resulting new segment is large
(perhaps $\frac{1}{2}$ the size of the containing segment).  The ideal
selection of $s$ and $d$ are shown for a particular selection of $c$
in \figsub{param}{c}.
\begin{figure}[htbp]
\centering
\subfloat[]{\includegraphics[width=0.30\linewidth]{fig/cca}}
\hspace{0.1em}
\subfloat[]{\includegraphics[width=0.30\linewidth]{fig/ccc.pdf}}
\hspace{0.1em}
\subfloat[]{\includegraphics[width=0.30\linewidth]{fig/ccb}}
\caption{} \label{fig:param}
\end{figure}

To obtain an estimation of $s$ we begin by setting $s$ a distance $0$
from the annotated point $c$.  We incrementally increase $s$ by a
small $\epsilon$ amount until the entire circle is within $\epsilon$
of the boundary of the containing segment.  Similar to this, we obtain
an estimation of $d$ by starting it at the estimated size of $s$, and
then incrementally increase it by $\epsilon$.  There is not a simple
stopping criterion to know undoubtedly that $d$ covers the entire
substructure desired.  However, we observe that if we separate the
containing segment into a background, and everything outside of the
containing segment into foreground, and we stop increasing $d$ when it
encompasses two, connected foreground regions, we tend to obtain a
large-enough value for $d$.  If this stopping condition never occurs,
we enforce a fixed maximum for $d$.  An illustration is given in
\fig{d-size}, where the $d$ size (blue circle) is not large enough in
\figsub{d-size}{a} and contains only a single connected foreground
component, whereas in \figsub{d-size}{b}, the $d$ size contains two
disjoint foreground regions, thus meeting the stopping criteria.
\begin{figure}[htbp]
\centering
\subfloat[Single foreground component]{\includegraphics[width=0.30\linewidth]{fig/cce}}
\hspace{0.1em}
\subfloat[Two foreground components]{\includegraphics[width=0.30\linewidth]{fig/ccd.pdf}}
\caption{} \label{fig:d-size}
\end{figure}

\section{Experiments}
\label{sec:ex}

\section{Conclusion}
\label{sec:conclusion}

\bibliography{matsci}
\bibliographystyle{spiebib}   %>>>> makes bibtex use spiebib.bst

\end{document} 
